{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import ast #############################\n",
    "import webbrowser ######################\n",
    "import textwrap\n",
    "import math\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer #######################\n",
    "from sklearn.cluster import KMeans ##########################\n",
    "from sklearn.preprocessing import MinMaxScaler #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_texts_dir = 'scraped_texts'\n",
    "processed_texts_dir = 'processed_texts'\n",
    "os.makedirs(scraped_texts_dir, exist_ok=True)\n",
    "os.makedirs(processed_texts_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_search_page(url):\n",
    "    uClient = uReq(url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, 'html.parser')\n",
    "    containers = page_soup.findAll('div', {'class':'highwire-cite highwire-cite-highwire-article highwire-citation-biorxiv-article-pap-list clearfix'})\n",
    "    return containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_results():\n",
    "    search_term = searchfield.get()\n",
    "    search_term = search_term.split(' ')\n",
    "    search_term = '%252B'.join(search_term)\n",
    "    site = sites.get()\n",
    "    first_part = 'https://www.' + site + '.org/search/'\n",
    "    search_url = first_part + search_term + '%20numresults%3A10%20sort%3Apublication-date%20direction%3Adescending' \n",
    "    ########################################################################################\n",
    "    #search_url = 'some other url here' #if you would like to input a full custom search url\n",
    "    ########################################################################################\n",
    "    uClient = uReq(search_url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, 'html.parser')\n",
    "    \n",
    "    num = re.findall(r'\\d+',page_soup.h1.text.strip())\n",
    "    if num:\n",
    "        num_results = int(''.join(num))\n",
    "        l3_string.set(str(num_results) + ' results found. Retrieve papers? Sorted by newest to oldest.')   \n",
    "        max_results = []\n",
    "        for pages in range(math.ceil(num_results/10)):\n",
    "            if (pages+1) == (math.ceil(num_results/10)):\n",
    "                max_results.append(str((pages)*10+num_results % 10) + ' max results')\n",
    "            else:\n",
    "                max_results.append(str((pages+1)*10) + ' max results')\n",
    "\n",
    "        maxresults['values'] = max_results\n",
    "        maxresults.grid(row = 1, column = 6, sticky = E, pady = 2) \n",
    "        collectbtn.grid(row = 1, column = 7, sticky = E, pady = 2)\n",
    "        \n",
    "    else:\n",
    "        l3_string.set('No results found')\n",
    "        maxresults.grid_forget()\n",
    "        collectbtn.grid_forget()\n",
    "\n",
    "\n",
    "    return num_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article_page(url): \n",
    "    uClient = uReq(url+'.full')\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, 'html.parser')\n",
    "\n",
    "    date = page_soup.findAll('div',{'class':'panel-pane pane-custom pane-1'})[0].div.text.strip()\n",
    "    date = re.sub('\\.','',date[7:])\n",
    "\n",
    "    article_soup = page_soup.find_all('div',{'class':re.compile('^article ')})[0]\n",
    "\n",
    "    for toremove in article_soup.find_all(id=[re.compile('^F\\d'),(re.compile('^T\\d'))]):\n",
    "        toremove.decompose()\n",
    "#     for toremove in article_soupfind_all('span'):\n",
    "#         toremove.decompose()\n",
    "    for toremove in article_soup.find_all('a',{'class':'xref-bibr'}):\n",
    "        toremove.decompose()\n",
    "    for toremove in article_soup.find_all('a',{'class':'xref-fig'}):\n",
    "        toremove.decompose()\n",
    "    for toremove in article_soup.find_all('sup'):\n",
    "        toremove.decompose()\n",
    "\n",
    "    main_titles = []\n",
    "    subtitles = []\n",
    "    curr_section = []\n",
    "\n",
    "    abstract = []\n",
    "    introduction = []\n",
    "    results = []\n",
    "    methods = []\n",
    "    discussion = []\n",
    "    \n",
    "    intro = False\n",
    "    for title in article_soup.find_all('h2'):\n",
    "        if ('introduction' in (title.text).lower()) | ('main' in (title.text).lower()):\n",
    "            intro = True #for dealing with labeling inconsistencies for introduction sections\n",
    "\n",
    "\n",
    "    for tag in article_soup.find_all(True):\n",
    "        if (re.match('^h', tag.name)):\n",
    "            if tag.name == 'h2':\n",
    "                main_titles.append(tag.text.lower())\n",
    "                curr_section = tag.text.lower()\n",
    "            else:\n",
    "                subtitles.append(tag.text.lower())\n",
    "        if (re.match('^p', tag.name)):\n",
    "            if ('abstract' in curr_section) | ('summary' in curr_section):\n",
    "                if (intro == False) & (len(abstract)>0):  # sometimes abstracts go straight into introductions on e.g. biorxiv\n",
    "                    introduction += [tag.text]\n",
    "                else:\n",
    "                    abstract += [tag.text]\n",
    "            if ('introduction' in curr_section) | ('main' in curr_section):\n",
    "                introduction += [tag.text]\n",
    "            if 'results' in curr_section:\n",
    "                results += [tag.text]\n",
    "            if 'methods' in curr_section:\n",
    "                methods += [tag.text]\n",
    "            if 'discussion' in curr_section:\n",
    "                discussion += [tag.text]\n",
    "        \n",
    "    return abstract, introduction, results, methods, discussion, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers(search_url, filename, max_pages):\n",
    "    uClient = uReq(search_url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, 'html.parser')   \n",
    "    num_pages = max_pages\n",
    "    page_num = 0\n",
    "\n",
    "    title = []\n",
    "    authors = []\n",
    "    date = []\n",
    "    paper_url = []\n",
    "\n",
    "    while page_num < num_pages:\n",
    "        if page_num == 0:\n",
    "            page_url = search_url\n",
    "\n",
    "        else:\n",
    "            page_url = search_url + '?page=' + str(page_num)\n",
    "\n",
    "        for container in read_search_page(page_url):\n",
    "            result_url = 'https://www.biorxiv.org' + container.a['href']  \n",
    "            paper_url.append(result_url)\n",
    "            title.append(container.a.span.text)\n",
    "            result_authors = container.findAll('span', {'class':'highwire-citation-authors'})[0].text\n",
    "            authors.append(result_authors)\n",
    "\n",
    "        page_num += 1\n",
    "\n",
    "\n",
    "    abstract = []\n",
    "    introduction = []\n",
    "    methods = []\n",
    "    results = []\n",
    "    discussion = []\n",
    "    \n",
    "    num_urls = len(paper_url)\n",
    "    progress1 = ttk.Progressbar(topleftframe, orient = HORIZONTAL, length=100, mode = 'determinate')\n",
    "    progress1.grid(row = 1, column = 8, sticky = E, pady = 2) \n",
    "    i = 1\n",
    "    \n",
    "    for url in tqdm(paper_url):\n",
    "        abst, intr, rslt, methd, disc, dt = read_article_page(url)\n",
    "        abstract += [abst]\n",
    "        introduction += [intr]\n",
    "        results += [rslt]\n",
    "        methods += [methd]\n",
    "        discussion += [disc]\n",
    "        date += [dt]\n",
    "        progress1[\"value\"] = i*100/num_urls\n",
    "        l3_string.set(f'Scraping paper {i} of {num_urls}')\n",
    "        root.update()\n",
    "        i += 1              \n",
    "        \n",
    "    progress1.grid_remove()\n",
    "    df = pd.DataFrame(list(zip(title, authors, date, paper_url, abstract, introduction, results, methods, discussion)),\n",
    "                          columns = ['Title','Authors','Date','Paper Url','Abstract', 'Introduction', 'Results', 'Methods', 'Discussion'])\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_json(filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_articles(dataframe):\n",
    "    abbreviated_texts = []\n",
    "    average_sentences = []\n",
    "    average_embeddings = []\n",
    "    keywords = []\n",
    "\n",
    "    num_articles = dataframe.shape[0]\n",
    "    progress2 = ttk.Progressbar(topleftframe, orient = HORIZONTAL, length=100, mode = 'determinate')\n",
    "    progress2.grid(row = 1, column = 8, sticky = E, pady = 2) \n",
    "    progress_idx = 1\n",
    "        \n",
    "    with tqdm(total=num_articles) as pbar: \n",
    "        for row in dataframe.itertuples(index=True):\n",
    "            pbar.update(1)\n",
    "            text = row[5:10]\n",
    "            merged_text = []\n",
    "            abbreviated_article = []\n",
    "\n",
    "            for i, section in enumerate(text):\n",
    "                section_avg_sentences = []\n",
    "                for j, paragraph in enumerate(section):\n",
    "                    shorter_paragraph = []\n",
    "                    paragraph = re.sub(' \\([^)]*\\)', '', paragraph) #removing parentheses\n",
    "                    paragraph = re.sub(' \\[.*?\\]', '', paragraph) #removing brackets\n",
    "\n",
    "                    para_avg_sentence, _ = return_average_sentences(paragraph)                \n",
    "                    merged_text.append(paragraph)                \n",
    "\n",
    "                    section_avg_sentences.append(para_avg_sentence[0])\n",
    "                abbreviated_article.append(section_avg_sentences)\n",
    "            abbreviated_texts.append(abbreviated_article)\n",
    "            merged_text = ' '.join(merged_text)\n",
    "            keywords_article = get_keywords([merged_text])\n",
    "            keywords.append(keywords_article)\n",
    "            sentence, average_embed = return_average_sentences(merged_text)\n",
    "            #sentence = paraphrase_shorten(sentence[0])\n",
    "            average_sentences.append(sentence) \n",
    "            average_embeddings.append(average_embed)\n",
    "            \n",
    "            progress2[\"value\"] = progress_idx*100/num_articles\n",
    "            l3_string.set(f'Processing paper {progress_idx+1} of {num_articles}')\n",
    "            root.update()\n",
    "            progress_idx += 1\n",
    "            \n",
    "    dataframe['Average Text'] = abbreviated_texts\n",
    "    dataframe['Average Sentence'] = average_sentences\n",
    "    dataframe['Average Embedding'] = average_embeddings\n",
    "    dataframe['Keywords'] = keywords\n",
    "    \n",
    "    progress2.grid_remove()\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def return_average_sentences(text, num_returned=1):\n",
    "    returned = num_returned\n",
    "\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "\n",
    "    embeds = model.encode(sentences)\n",
    "    avg = sum(embeds) / len(embeds)    \n",
    "    cosim = cosine_similarity([avg], embeds)   \n",
    "    #keysentences1 = [sentences[idx] for idx in summed.argsort()[-returned:]]  ###same results as doing averages...\n",
    "    average_sentences = [sentences[idx] for idx in cosim.argsort()[0][-returned:]]\n",
    "    \n",
    "    return average_sentences, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Largely from: https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea\n",
    "def get_keywords(text):\n",
    "    n_gram_range = (1, 1)\n",
    "    returned = 5\n",
    "        \n",
    "    count = CountVectorizer(ngram_range=n_gram_range, stop_words='english').fit(text)\n",
    "    words = count.get_feature_names()\n",
    "    gen_embedding = model.encode(text)\n",
    "    word_embeddings = model.encode(words)\n",
    "    cosim = cosine_similarity(gen_embedding, word_embeddings)\n",
    "    keywords = [words[idx] for idx in cosim.argsort()[0][-returned:]]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_papers(dataframe):\n",
    "    X = dataframe['Average Embedding'].tolist()\n",
    "    k_rng = range(1,int(len(X)/(1.5)))\n",
    "    sse = []\n",
    "    for k in k_rng:\n",
    "        km = KMeans(n_clusters=k)\n",
    "        km.fit(X)\n",
    "        sse.append(km.inertia_)\n",
    "\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Sum of squared error')\n",
    "    plt.plot(k_rng, sse)\n",
    "\n",
    "    x1 = k_rng[0]\n",
    "    y1 = sse[0]\n",
    "    x2 = k_rng[-1]\n",
    "    y2 = sse[-1]\n",
    "\n",
    "    x = [x1, x2]\n",
    "    y = [y1, y2]\n",
    "    coefficients = np.polyfit(x, y, 1)\n",
    "    polynom = np.poly1d(coefficients)\n",
    "    x = np.array(k_rng)\n",
    "    y = polynom(x)\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "    p1 = np.array([x1, y1])\n",
    "    p2 = np.array([x2, y2])\n",
    "    distance = []\n",
    "\n",
    "    for x, y in zip(k_rng, sse):\n",
    "        p3 = np.array([x, y])\n",
    "        d = np.linalg.norm(np.cross(p2-p1, p1-p3))/np.linalg.norm(p2-p1)\n",
    "        distance.append(d)\n",
    "\n",
    "    num_clusters = np.argmax(distance)   #admittedly likely not as good as using the standard elbow method\n",
    "\n",
    "    if num_clusters > 50:\n",
    "        raise NameError('Too many clusters (over 50)')\n",
    "\n",
    "    km = KMeans(n_clusters=num_clusters)\n",
    "    y_predicted = km.fit_predict(X)\n",
    "    centers = km.cluster_centers_\n",
    "\n",
    "    dataframe['Cluster'] = y_predicted\n",
    "    dataframe['Centers'] = dataframe['Cluster'].apply(lambda x: centers[x])\n",
    "\n",
    "    dataframe = dataframe.sort_values('Cluster')\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_keywords(dataframe):\n",
    "    cluster_keywords = []\n",
    "    clusters = dataframe['Cluster'].unique()\n",
    "    for cluster in clusters:\n",
    "        cluster_text = []\n",
    "        for sentence in dataframe['Average Sentence'][dataframe.Cluster==cluster]:\n",
    "            cluster_text.append(sentence[0])\n",
    "        keywords = get_keywords(cluster_text)\n",
    "        cluster_keywords.append(keywords)\n",
    "    dataframe['Cluster Keywords'] = dataframe['Cluster'].apply(lambda x: cluster_keywords[x])\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_center_sort(dataframe):\n",
    "    center_proximity = []\n",
    "    clusters = dataframe['Cluster'].unique()\n",
    "    for cluster in clusters:\n",
    "        cluster_embeddings = []\n",
    "        cluster_center = (dataframe['Centers'][dataframe.Cluster==cluster].tolist())[0]\n",
    "        for embedding in dataframe['Average Embedding'][dataframe.Cluster==cluster]:\n",
    "            cluster_embeddings.append(embedding)\n",
    "        order = range(0, len(embedding-1))\n",
    "        cosim = cosine_similarity([cluster_center], cluster_embeddings)\n",
    "        center_proximity = np.concatenate((center_proximity, *cosim))\n",
    "    dataframe['Center Proximity'] = center_proximity\n",
    "    \n",
    "    dataframe = dataframe.sort_values(['Center Proximity'], ascending=False)\n",
    "    dataframe = dataframe.sort_values(['Cluster'])\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biorxiv_search(search_url, filename, max_results):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ################################################################\n",
    "    max_pages = math.ceil(max_results/10)\n",
    "    \n",
    "    print('Scraping papers')\n",
    "    #l3_string.set('Scraping papers')\n",
    "    \n",
    "    df = get_papers(search_url, filename, max_pages)\n",
    "    \n",
    "    df.to_excel('scraped_texts/'+filename+'.xlsx', index=False)\n",
    "    #df.to_json('scraped_texts/'+filename+'.csv')\n",
    "    df.to_pickle('scraped_texts/'+filename+'.df')\n",
    "    \n",
    "    ##############################################################\n",
    "    print('Processing papers')\n",
    "    #l3_string.set('Processing papers')\n",
    "    df = process_articles(df)\n",
    "\n",
    "    df = cluster_papers(df)  \n",
    "    df = get_cluster_keywords(df)\n",
    "    \n",
    "    df = cluster_center_sort(df)\n",
    "    \n",
    "    if not os.path.exists('processed_texts/'):\n",
    "        os.makedirs('processed_texts/')\n",
    "    \n",
    "    #df.to_excel('processed_texts/'+filename+'.xlsx', index=False)\n",
    "    df.to_pickle('processed_texts/'+filename+'.df')\n",
    "    \n",
    "    end_time = time.time() \n",
    "    duration = (end_time-start_time)\n",
    "    duration = round(duration, 2)\n",
    "    time_unit = ' seconds'\n",
    "    if duration > 60:\n",
    "        time_unit = ' minutes'\n",
    "        duration = duration/60 \n",
    "        \n",
    "    duration = str(duration) + time_unit\n",
    "    num_results = len(df)\n",
    "\n",
    "    print('Retrieval complete. Total time: ' + duration)\n",
    "    \n",
    "    \n",
    "    return df, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_shorten(text):\n",
    "\n",
    "    encoding = tokenizer_para.encode_plus(text,padding='longest', return_tensors='pt')\n",
    "    input_ids, attention_masks = encoding['input_ids'], encoding['attention_mask']\n",
    "\n",
    "    outputs = model_para.generate(input_ids=input_ids, attention_mask=attention_masks, max_length=256, do_sample=True, top_k=70, top_p=0.99, early_stopping=False, num_return_sequences=3)\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for output in outputs:\n",
    "        line = tokenizer_para.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        lines.append(line)\n",
    "    lines.append(text)\n",
    "    lenlines = np.array([len(x) for x in lines]).argsort()\n",
    "    shortest_line = lines[lenlines[0]]\n",
    "\n",
    "    return shortest_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(string, length=8):\n",
    "    return '\\n'.join(textwrap.wrap(string, length))\n",
    "\n",
    "def abbrev_names(names):\n",
    "    abbrvnames = ''\n",
    "    if len(names) == 3:\n",
    "        abbrvnames = abbrev_name(names[0]) + ', ' + abbrev_name(names[1]) + ', and ' + abbrev_name(names[2])\n",
    "    if len(names) == 2:\n",
    "        abbrvnames = abbrev_name(names[0]) + ', and ' + abbrev_name(names[1])\n",
    "    if len(names) == 1:\n",
    "        abbrvnames = abbrev_name(names[0])\n",
    "    else:\n",
    "        abbrvnames = abbrev_name(names[0]) + ' et al.'\n",
    "    return abbrvnames\n",
    "\n",
    "def abbrev_name(name):\n",
    "    abbrvname = name.split(' ')\n",
    "    surname = abbrvname[-1]\n",
    "    givennames = ' '.join(abbrvname[:-1])\n",
    "    abbrvname = ''.join(re.findall('[A-Z]', givennames)) + ' ' + surname\n",
    "    return abbrvname\n",
    "\n",
    "def on_web_click(event):\n",
    "    url = url_string.get()\n",
    "    webbrowser.open(url)\n",
    "\n",
    "    \n",
    "def on_double_click(event):\n",
    "    item_id = event.widget.focus()\n",
    "    item = event.widget.item(item_id)\n",
    "    values=item['values']\n",
    "    title=' '.join((values[3]).split('\\n'))\n",
    "    authors=values[1]\n",
    "    date=' '.join((values[2]).split('\\n'))\n",
    "    url=values[4]\n",
    "    keywords=values[5]\n",
    "    \n",
    "    titletext.config(state=NORMAL)\n",
    "    bodytext.config(state=NORMAL)\n",
    "    titletext.delete('1.0', END)\n",
    "    bodytext.delete('1.0', END)\n",
    "    \n",
    "    a, i, r, m, d = values[6], values[7], values[8], values[9], values[10]\n",
    "    \n",
    "    if len(a) > 1:\n",
    "        bodytext.insert(END, 'ABSTRACT\\n', 'heading')\n",
    "        bodytext.insert(END, a+'\\n\\n', 'body')\n",
    "        \n",
    "    if len(i) > 1:\n",
    "        bodytext.insert(END, 'INTRODUCTION\\n', 'heading')\n",
    "        bodytext.insert(END, i+'\\n\\n', 'body')\n",
    "        \n",
    "    if len(d) > 1:\n",
    "        bodytext.insert(END, 'DISCUSSION\\n', 'heading')\n",
    "        bodytext.insert(END, d+'\\n\\n', 'body')\n",
    "    \n",
    "    if len(r) > 1:\n",
    "        bodytext.insert(END, 'RESULTS\\n', 'heading')\n",
    "        bodytext.insert(END, r+'\\n\\n', 'body')\n",
    "    \n",
    "    if len(m) > 1:\n",
    "        bodytext.insert(END, 'METHODS\\n', 'heading')\n",
    "        bodytext.insert(END, m+'\\n\\n', 'body')\n",
    "        \n",
    "    \n",
    "    title_text = title + '\\n' + authors + '\\n' + date# + '\\n' + keywords\n",
    "    titletext.insert(END, title_text, 'title')\n",
    "    \n",
    "    titletext.config(state=DISABLED)\n",
    "    bodytext.config(state=DISABLED)\n",
    "    \n",
    "    url_string.set(url)\n",
    "    \n",
    "def oldsearches(event):\n",
    "    file =  'processed_texts/'+searches.get()\n",
    "    currdf = pd.read_pickle(file+'.df')\n",
    "    remove_data()\n",
    "    add_data(currdf)\n",
    "    \n",
    "def search():\n",
    "    max_results = maxresults.get()\n",
    "    max_results = int(''.join(re.findall('\\d', max_results)))\n",
    "    \n",
    "    maxresults.grid(row = 1, column = 5, sticky = E, pady = 2) \n",
    "    collectbtn.grid(row = 1, column = 6, sticky = E, pady = 2)\n",
    "    maxresults.grid_forget()\n",
    "    collectbtn.grid_forget()\n",
    "    \n",
    "    search_term = searchfield.get()\n",
    "    filename = search_term\n",
    "    search_term = search_term.split(' ')\n",
    "    search_term = '%252B'.join(search_term)\n",
    "    site = str(sites.get())\n",
    "    first_part = 'https://www.' + site + '.org/search/'\n",
    "    search_url = first_part + search_term + '%20numresults%3A10%20sort%3Apublication-date%20direction%3Adescending' \n",
    "    newdf, duration = biorxiv_search(search_url, filename, max_results)\n",
    "\n",
    "    remove_data()\n",
    "    add_data(newdf) \n",
    "    l3_string.set(('Retrieval complete. Total time: {}. Retrieved {} articles').format(duration, len(newdf)))\n",
    "    \n",
    "def add_data(df):\n",
    "    clusters = (df['Cluster'].unique())\n",
    "    l4_string.set(str(len(df)) + ' articles found')\n",
    "    for cluster in clusters:\n",
    "        keywords = ', '.join(df['Cluster Keywords'][df.Cluster==cluster].tolist()[0])\n",
    "        tree.insert(parent='', index='end', iid=cluster+1, text=str(cluster+1), values=(keywords,'','','',''), tags=('parent',))\n",
    "    \n",
    "    for idx, cluster, title, url, authors, date, avg_sentence, keywords, text in zip(df.index, df.Cluster, df.Title, df['Paper Url'], df.Authors, df.Date, df['Average Sentence'], df['Keywords'],df['Average Text']):\n",
    "        paper_url = url\n",
    "        authors = abbrev_names(authors.split(', '))\n",
    "        tree.insert(parent=(cluster+1), index='end', iid=idx+len(clusters)+1, text='', values=(wrap(avg_sentence[0], 85), authors, wrap(date,10), wrap(title,40), url, keywords, \n",
    "                                                                                               '\\u2022' + '\\n\\u2022'.join(text[0]), \n",
    "                                                                                               '\\u2022' + '\\n\\u2022'.join(text[1]), \n",
    "                                                                                               '\\u2022' + '\\n\\u2022'.join(text[2]), \n",
    "                                                                                               '\\u2022' + '\\n\\u2022'.join(text[3]), \n",
    "                                                                                               '\\u2022' + '\\n\\u2022'.join(text[4])))\n",
    "\n",
    "def remove_data():\n",
    "    tree.delete(*tree.get_children())\n",
    "    l3_string.set('')\n",
    "    l4_string.set('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping papers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94048c212b341d996f4a91f220ca0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing papers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee30988027574a38bcf176152c5b099b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval complete. Total time: 2.2445 minutes\n"
     ]
    }
   ],
   "source": [
    "root = Tk()\n",
    "root.title('Preprint summarizer')\n",
    "root.geometry('1530x900')\n",
    "root.grid_propagate(False)\n",
    "\n",
    "\n",
    "old_searches = []\n",
    "if not os.path.exists('processed_texts/'):\n",
    "        os.makedirs('processed_texts/')\n",
    "for file in os.listdir('processed_texts/'):\n",
    "    if file.endswith('.df'):\n",
    "        old_searches.append(file[:-3])\n",
    "        \n",
    "l3_string = StringVar(value='')\n",
    "l4_string = StringVar(value='')\n",
    "url_string = StringVar(value='')\n",
    "\n",
    "#################################################################################\n",
    "mainframe = Frame(root)\n",
    "mainframe.pack(expand=True, fill=BOTH, padx=25, pady=10, anchor=NW)\n",
    "\n",
    "topframe = Frame(mainframe)\n",
    "topframe.pack(side=TOP, anchor=NW, expand=False, fill=X)\n",
    "\n",
    "botframe = Frame(mainframe)\n",
    "botframe.pack(side=BOTTOM, anchor=NW, expand=True, fill=Y, pady=2)\n",
    "\n",
    "topleftframe = Frame(topframe)\n",
    "topleftframe.pack(side=LEFT, anchor=NW, expand=False)\n",
    "\n",
    "\n",
    "botleftframe = Frame(botframe)\n",
    "botleftframe.pack(side=LEFT, anchor=NW, expand=True, fill=Y)\n",
    "\n",
    "botrightframe = Frame(botframe)\n",
    "botrightframe.pack(side=RIGHT, anchor=NW, expand=True, fill=Y, padx=15)\n",
    "##################################################################################\n",
    "\n",
    "l0 = Label(topleftframe, text = \"Website:\")\n",
    "l0.grid(row = 1, column = 1, sticky = W)\n",
    "\n",
    "sites = ttk.Combobox(topleftframe, height=1, width=35)\n",
    "sites['values'] = ['biorxiv','medrxiv']\n",
    "sites.current(0)\n",
    "sites.grid(row = 1, column = 2, sticky = W, pady=2, padx=2)\n",
    "\n",
    "l1 = Label(topleftframe, text = \"Search:\")\n",
    "l1.grid(row = 1, column = 3, sticky = W)\n",
    "\n",
    "searchfield = Entry(topleftframe, width=38)\n",
    "searchfield.grid(row = 1, column = 3, sticky = W, padx=2)\n",
    "\n",
    "searchbtn = Button(topleftframe, text='Search', command=get_num_results)\n",
    "searchbtn.grid(row = 1, column = 4, sticky = W)\n",
    "\n",
    "collectbtn = Button(topleftframe, text='Retrieve', command=search)\n",
    "maxresults = ttk.Combobox(topleftframe, height=1, width=15)\n",
    "\n",
    "l2 = Label(topleftframe, text = \"Past searches:\")\n",
    "l2.grid(row = 2, column = 1, sticky = W)\n",
    "\n",
    "searches = ttk.Combobox(topleftframe, height=1, width=35)\n",
    "searches['values'] = old_searches\n",
    "searches.bind(\"<<ComboboxSelected>>\", oldsearches)\n",
    "searches.grid(row = 2, column = 2, sticky = W, pady=2)\n",
    "\n",
    "l3 = Label(topleftframe, textvariable=l3_string)\n",
    "l3.grid(row = 1, column = 5, sticky = W, padx=5, pady=2)\n",
    "\n",
    "l4 = Label(topleftframe, textvariable=l4_string)\n",
    "l4.grid(row = 2, column = 3, sticky = W, padx=5, pady=2)\n",
    "\n",
    "# from tkinter.font import Font\n",
    "# font = Font(None, size=11)\n",
    "# l1.configure(font=font)\n",
    "# l2.configure(font=font)\n",
    "# l3.configure(font=font)\n",
    "# l4.configure(font=font)\n",
    "# searches.configure(font=font)\n",
    "# maxresults.configure(font=font)\n",
    "# collectbtn.configure(font=font)\n",
    "# searchbtn.configure(font=font)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "s = ttk.Style()\n",
    "#s.theme_use('default')\n",
    "s.configure('Treeview',rowheight=78)\n",
    "s.configure('Treeview.Heading', font=(None, 10))\n",
    "s.map('Treeview', background=[('selected','blue')])\n",
    "\n",
    "#'#E26D5C'\n",
    "\n",
    "tree = ttk.Treeview(botleftframe)\n",
    "tree.bind(\"<Double-Button-1>\", on_double_click)\n",
    "\n",
    "tree.tag_configure('parent', background='white', font=(None, 10, 'italic'))\n",
    "tree.tag_configure('oddrow', background='white')\n",
    "\n",
    "tree['columns'] = ('Average Sentence', 'Authors', 'Date', 'Title')\n",
    "\n",
    "tree.column('#0', width=50, minwidth=25)\n",
    "tree.column('Average Sentence', anchor=W, width=480)\n",
    "tree.column('Authors', anchor=W, width=100)\n",
    "tree.column('Date', anchor=W, width=70)\n",
    "tree.column('Title', anchor=W, width=250)\n",
    "\n",
    "tree.heading('#0', text='Cluster', anchor=W)\n",
    "tree.heading('Average Sentence', text='Average Sentence', anchor=W)\n",
    "tree.heading('Authors', text='Authors', anchor=W)\n",
    "tree.heading('Date', text='Date', anchor=CENTER)\n",
    "tree.heading('Title', text='Title', anchor=W)\n",
    "\n",
    "tree.pack(side=LEFT, expand=True, fill=BOTH, anchor=NW, pady=2)\n",
    "\n",
    "textcanvas = Canvas(botrightframe, background='white', relief='groove', bd=1)\n",
    "textcanvas.pack(expand=True, fill=BOTH, anchor=NW)\n",
    "\n",
    "titletext= Text(textcanvas, bd=0, height=6)\n",
    "titletext.tag_configure('title', font=(None, 11, 'italic'))\n",
    "titletext.bind('<Double-Button-1>', on_web_click)\n",
    "titletext.pack(side=TOP, expand=False, fill=X, anchor=NW, padx=10, pady=5)\n",
    "\n",
    "bodytext = Text(textcanvas, bd=0)\n",
    "bodytext.tag_configure('body', font=(None, 10))\n",
    "bodytext.tag_configure('heading', font=(None, 11))\n",
    "bodytext.pack(side=LEFT, expand=True, fill=BOTH, anchor=NW, padx=10, pady=5)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
